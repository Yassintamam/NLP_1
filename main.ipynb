{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "dataset = load_dataset(\"sst\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "#naive bayes\n",
    "def train_naive_bayes(D, C):\n",
    "    N_doc = len(D)\n",
    "    logprior = {}\n",
    "    loglikelihood = {}\n",
    "    V = set()\n",
    "    bigdoc = defaultdict(list)\n",
    "    word_counts_per_class = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    # Calculate logprior and collect documents for each class\n",
    "    for c in C:\n",
    "        D_c = [doc_tokens for doc_tokens, cl in D if cl == c]\n",
    "        N_c = len(D_c)\n",
    "        logprior[c] = np.log(N_c / N_doc)\n",
    "        for doc in D_c:\n",
    "            bigdoc[c] += doc\n",
    "            V.update(doc)\n",
    "            for word in doc:\n",
    "                word_counts_per_class[word][c] += 1\n",
    "\n",
    "    V = list(V)\n",
    "\n",
    "    # Calculate loglikelihood\n",
    "    for w in V:\n",
    "        for c in C:\n",
    "            count_w_c = word_counts_per_class[w][c]\n",
    "            loglikelihood[(w, c)] = np.log((count_w_c + 1) / (sum(word_counts_per_class[w].values()) + len(V)))\n",
    "\n",
    "    return logprior, loglikelihood, V\n",
    "\n",
    "def test_naive_bayes(testdoc, logprior, loglikelihood, C, V):\n",
    "    sum_scores = {c: logprior[c] for c in C}\n",
    "    for word in testdoc:\n",
    "        if word in V:\n",
    "            for c in C:\n",
    "                sum_scores[c] += loglikelihood.get((word, c), 0)\n",
    "    return max(sum_scores, key=sum_scores.get)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "classes = {\n",
    "    0: \"Very Negative\",\n",
    "    1: \"Negative\",\n",
    "    2: \"Neutral\",\n",
    "    3: \"Positive\",\n",
    "    4: \"Very Positive\",\n",
    "}\n",
    "def map_dataset(data):\n",
    "    if data <= 0.2:\n",
    "        return 0  # very negative\n",
    "    elif data <= 0.4:\n",
    "        return 1  # negative\n",
    "    elif data <= 0.6:\n",
    "        return 2  # neutral\n",
    "    elif data <= 0.8:\n",
    "        return 3  # positive\n",
    "    else:\n",
    "        return 4  # very positive\n",
    "def data_to_tokens(data):\n",
    "    documents = []\n",
    "    for entry in data:\n",
    "        tokens = entry['tokens'].split(\"|\")\n",
    "        label = map_dataset(entry['label'])\n",
    "        documents.append((tokens, label))\n",
    "    return documents"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# Prepare training and testing data\n",
    "train_documents = data_to_tokens(dataset['train'])\n",
    "test_documents = data_to_tokens(dataset['test'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36742081447963804\n",
      "Random phrase: This movie was fantastic! I loved every minute of it.\n",
      "Predicted class: 1\n",
      "Actual class: 3\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes classifier\n",
    "logprior, loglikelihood, vocab_list = train_naive_bayes(train_documents, [0, 1, 2, 3, 4])\n",
    "\n",
    "# Test the classifier on the test dataset\n",
    "correct_predictions = 0\n",
    "total_predictions = len(test_documents)\n",
    "\n",
    "for doc_tokens, actual_class in test_documents:\n",
    "    predicted_class = test_naive_bayes(doc_tokens, logprior, loglikelihood, [0, 1, 2, 3, 4], vocab_list)\n",
    "    if predicted_class == actual_class:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Test the classifier on a sample document\n",
    "random_phrase = \"This movie was fantastic! I loved every minute of it.\"\n",
    "random_score = np.random.uniform(0, 1)\n",
    "actual_class = map_dataset(random_score)\n",
    "predicted_class = test_naive_bayes(random_phrase.split(), logprior, loglikelihood, [0, 1, 2, 3, 4], vocab_list)\n",
    "print(\"Random phrase:\", random_phrase)\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"Actual class:\", actual_class)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using scikit-learn: 0.4090497737556561\n"
     ]
    }
   ],
   "source": [
    "#comparison with sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare training and testing data\n",
    "train_texts = [' '.join(tokens) for tokens, _ in train_documents]\n",
    "test_texts = [' '.join(tokens) for tokens, _ in test_documents]\n",
    "train_labels = [label for _, label in train_documents]\n",
    "test_labels = [label for _, label in test_documents]\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "# Train the classifier\n",
    "pipeline.fit(train_texts, train_labels)\n",
    "\n",
    "# Predict on the test set\n",
    "predicted_labels = pipeline.predict(test_texts)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(\"Accuracy using scikit-learn:\", accuracy)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "# Feature representation\n",
    "def generate_bigrams_from_dataset(dataset):\n",
    "    bigrams = set()\n",
    "    for example in dataset:\n",
    "        tokens = example['tokens']\n",
    "        for i in range(len(tokens) - 1):\n",
    "            bigram = (tokens[i], tokens[i+1])\n",
    "            bigrams.add(bigram)\n",
    "    return sorted(list(bigrams))\n",
    "\n",
    "def generate_features_from_dataset(dataset, bigrams):\n",
    "    features = np.zeros((len(dataset), len(bigrams)), dtype=int)\n",
    "    for i, example in enumerate(dataset):\n",
    "        tokens = example['tokens']\n",
    "        for j, bigram in enumerate(bigrams):\n",
    "            if bigram in zip(tokens, tokens[1:]):\n",
    "                features[i, j] = 1\n",
    "    return features\n",
    "\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# Model Training\n",
    "def train_logistic_regression(X, y, learning_rate, num_iterations):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros((n, 1))\n",
    "    for i in range(num_iterations):\n",
    "        z = np.dot(X, theta)\n",
    "        h = sigmoid(z)\n",
    "        gradient = np.dot(X.T, (h - y)) / m\n",
    "        theta -= learning_rate * gradient\n",
    "    return theta"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# Prediction\n",
    "def predict(X, theta):\n",
    "    z = np.dot(X, theta)\n",
    "    h = sigmoid(z)\n",
    "    return (h >= 0.5).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.0027149321266968325\n"
     ]
    }
   ],
   "source": [
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]\n",
    "# Generate bigrams\n",
    "bigrams = generate_bigrams_from_dataset(train_data)\n",
    "# Generate features\n",
    "X_train = generate_features_from_dataset(train_data, bigrams)\n",
    "y_train = np.array(train_data['label']).reshape(-1, 1)\n",
    "X_test = generate_features_from_dataset(test_data, bigrams)\n",
    "y_test = np.array(test_data['label']).reshape(-1, 1)\n",
    "# Train logistic regression\n",
    "learning_rate = 0.01\n",
    "num_iterations = 1000\n",
    "theta = train_logistic_regression(X_train, y_train, learning_rate, num_iterations)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = predict(X_test, theta)\n",
    "accuracy_score = accuracy(y_test, y_pred)\n",
    "print(\"Test accuracy:\", accuracy_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[49], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Train logistic regression using scikit-learn\u001B[39;00m\n\u001B[0;32m      5\u001B[0m lr \u001B[38;5;241m=\u001B[39m LogisticRegression()\n\u001B[1;32m----> 6\u001B[0m \u001B[43mlr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m y_pred_sklearn \u001B[38;5;241m=\u001B[39m lr\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Evaluate scikit-learn model accuracy\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[1;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1209\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1199\u001B[0m     _dtype \u001B[38;5;241m=\u001B[39m [np\u001B[38;5;241m.\u001B[39mfloat64, np\u001B[38;5;241m.\u001B[39mfloat32]\n\u001B[0;32m   1201\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[0;32m   1202\u001B[0m     X,\n\u001B[0;32m   1203\u001B[0m     y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1207\u001B[0m     accept_large_sparse\u001B[38;5;241m=\u001B[39msolver \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msag\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaga\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   1208\u001B[0m )\n\u001B[1;32m-> 1209\u001B[0m \u001B[43mcheck_classification_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1210\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y)\n\u001B[0;32m   1212\u001B[0m multi_class \u001B[38;5;241m=\u001B[39m _check_multi_class(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmulti_class, solver, \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_))\n",
      "File \u001B[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:221\u001B[0m, in \u001B[0;36mcheck_classification_targets\u001B[1;34m(y)\u001B[0m\n\u001B[0;32m    213\u001B[0m y_type \u001B[38;5;241m=\u001B[39m type_of_target(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    219\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel-sequences\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    220\u001B[0m ]:\n\u001B[1;32m--> 221\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown label type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Maybe you are trying to fit a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    223\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclassifier, which expects discrete classes on a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    224\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mregression target with continuous values.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    225\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "#sklearn comparison\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train logistic regression using scikit-learn\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_sklearn = lr.predict(X_test)\n",
    "\n",
    "# Evaluate scikit-learn model accuracy\n",
    "accuracy_score_sklearn = accuracy(y_true, y_pred_sklearn)\n",
    "print(\"Accuracy of scikit-learn logistic regression:\", accuracy_score_sklearn)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
